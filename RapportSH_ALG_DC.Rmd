---
title: "Rapport TDDeepLearning"
author: "Salomé Hamard, Anne-Laure Girard, Dylan Clair"
date: "6 mai 2020"
output: html_document
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Notre projets

## Domaine
Nous avons décidé de prendre des animaux à reconnaitre. 

## Catégories
Il est néessaire que le choix des cathégories soit assez large car la reconnaissance de différances infimes n'apporterait aucuns résultats concluents.
Nous avons donc choisi es catégories Ornithorynque, Licorne et Canard.

## Remarques sur la constitution du corpus d'apprentissage
La construction d'un corpus d'apprentissage est complexe. Il est nécessaire d'avoir une bonne base de donnée pour que le programme ait assez de renseignement sur le sujet, et qu'il sache identfié n'importe quelle image traitant d'un même sujet sans ce tromper. Il faut éviter les mauvaises données, qui pourai endomager le corpus d'apprentossage. Los de la construction de ce corpus cetaines images sont mises de côté par le programme car pas assez représentatives.
Nous avons importé 100 images pour chaque catégorie. Ce corpus d'apprentissage n'est pas très grand. Le travail du réseau neuronal sera donc pas très riche mais tout de même composé d'une base de donnée "propre". 

## Remarques sur la création de votre réseau neuronal et sa performance
Le réseau neuronal permet au logiciel de reconnaitre des informations nouvelles et de les identifier selon ce qu'il a appris.
Il est nécessaire de faire tourner le corpus d'apprentissage de nombreuses foi pour que le logiciel apprenne ce que nous souhaitons et soit performant. Mais il ne fait pas qu'il apprene trop les données que nous lui fournissons. Il ne serait plus adaptable à toute les situations que nous lui demanderons sur le sujet en question, et risquerait de se tromper.
Pour avoir une utilisation intéréssante de cet IA il faut que le logiciel reconnaisse à au moins 97% chaque catégorie de données. Cela nous indique que presque tout le temps il ne se trope pas sur son sujet, à condition que le jeu de donnée soit significatif (montre tous les aspects du sujet). Il faut aussi que le réseau neuronal soit performant pour tous les jeux de donnée que nous lui fournissons.
Par contre il ne fait pas surentrainer le réseau neronale, cela réduirait sa performance sur les données qu'il ne connait pas car n'arrive plus à faire les liens.

Au niveau de notre réseau neronal : 


# vos 3 fichiers de sauvegarde du réseau neuronal (.categories, .h5, *.json)

# Etudes de réseaux précédemment créés

# Produire également un graphique à partir du fichier models.csv

```{r plot1, include=FALSE}
library(ggplot2)

models <- read.csv("models.csv", sep=",",
                   colClasses = c(rep("numeric",2), "character", 
                                  rep("numeric",2), "character", 
                                  rep("numeric",2)), 
                   na.strings = "NA")

str(models)

names(models) <- c("Nb_classes", "Nb_neuro", "Dataset_train", "Nb_image_train", "Nb_passes", "Dataset_test", "Nb_image_test", "Tx_success")
models$Factor <- paste(models$Nb_neuro, models$Dataset_train)

#Graphe Tx de succés selon le nb de passes

png("plot1.png", width = 800, height = 600)
qplot(Nb_passes, Tx_success, data = models, color=Factor, geom = c("point", "line"))
dev.off()
```
```{r graphplot1, echo=FALSE, out.width='100%', fig.align="center"}

#Inclure le png du chunk r plot1

knitr::include_graphics("plot1.png")

```
--> Explication des résultats

# Remarques



